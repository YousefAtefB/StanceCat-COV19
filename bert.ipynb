{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK7AjxdBjW1Z"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/StanceCat-COV19"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWG1FbUr7TRn",
        "outputId": "ae6899c2-203e-4adc-e573-29028b83909d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/StanceCat-COV19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cg_iBd0RjW1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64cb780-27cb-43a9-9f28-60d3a8da3052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import re\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "nltk.download('punkt')\n",
        "from torch.optim import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfTzru_-jW1e"
      },
      "source": [
        "# Data PreProcessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrTbA7l-jW1f",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('Dataset/train.csv')\n",
        "text_train, category_train, stance_train = train['text'], train['category'], train['stance']\n",
        "\n",
        "dev = pd.read_csv('Dataset/dev.csv')\n",
        "text_dev, category_dev, stance_dev = dev['text'], dev['category'], dev['stance']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgkZM03DjW1g",
        "outputId": "cb6c843b-c624-4a3e-fb55-4b2408a19933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text   category  stance\n",
              "0  Ø¨ÙŠÙ„ ØºÙŠØªØ³ ÙŠØªÙ„Ù‚Ù‰ Ù„Ù‚Ø§Ø­ #ÙƒÙˆÙÙŠØ¯19 Ù…Ù† ØºÙŠØ± ØªØµÙˆÙŠØ± Ø§Ù„Ø§Ø¨...  celebrity       1\n",
              "1  ÙˆØ²ÙŠØ± Ø§Ù„ØµØ­Ø© Ù„Ø­Ø¯ Ø§Ù„ÙŠÙˆÙ… ÙˆØªØ­Ø¯ÙŠØ¯Ø§ Ù‡Ù„Ø£ Ø¨Ù…Ø¤ØªÙ…Ø±ÙˆØ§ Ø§Ù„ØµØ­...  info_news       1\n",
              "2  Ù‚ÙˆÙ„ÙƒÙ†  Ø±Ø­ ÙŠÙƒÙˆÙ†Ùˆ Ø§Ø¯ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠØ© Ø¨ Ù„Ø¨Ù†Ø§Ù† Ù„Ù…Ø§ ÙŠÙˆØµÙ„ ...  info_news       1\n",
              "3  #ØªØ±ÙƒÙŠØ§.. ÙˆØ²ÙŠØ± Ø§Ù„ØµØ­Ø© ÙØ®Ø± Ø§Ù„Ø¯ÙŠÙ† Ù‚ÙˆØ¬Ø© ÙŠØªÙ„Ù‚Ù‰ Ø£ÙˆÙ„ Ø¬...  celebrity       1\n",
              "4  ÙˆØ¦Ø§Ù… ÙˆÙ‡Ø§Ø¨ ÙŠØ´ØªÙ… Ø§Ù„Ø¯ÙˆÙ„ Ø§Ù„Ø®Ù„ÙŠØ¬ÙŠØ© ÙÙŠ ÙƒÙ„ Ø·Ù„Ø© Ø§Ø¹Ù„Ø§Ù…ÙŠ...   personal       0\n",
              "5  Ù„Ù‚Ø§Ø­ #ÙƒÙˆØ±ÙˆÙ†Ø§ ÙÙŠ Ø£Ù…ÙŠØ±ÙƒØ§.. Ù‚Ù„Ù‚ Ù…ØªØ²Ø§ÙŠØ¯ Ù…Ù† \"Ø§Ù„ØªÙˆØ²ÙŠ...  info_news       0\n",
              "6  Ù„Ø¨Ù†Ø§Ù† Ø§Ø´ØªØ±Ù‰ Ù…Ù„ÙŠÙˆÙ†Ø§Ù† Ù„Ù‚Ø§Ø­ Ø§Ù…Ø±ÙŠÙƒÙŠ Ø§Ø°Ø§ Ø´Ù„Ù†Ø§ ÙŠÙ„ÙŠ Ø¹...  info_news       1\n",
              "7  Ù…Ù† Ø¹ÙˆØ§Ø±Ø¶ Ù„Ù‚Ø§Ø­ ÙƒÙˆØ±ÙˆÙ†Ø§<LF>Ù‡Ùˆ ØªÙ‡ÙƒÙŠØ± Ø­Ø³Ø§Ø¨Ùƒ Ø¹ØªÙˆÙŠØªØ±<...   personal       0\n",
              "8  Ù‡Ù†Ø§Ùƒ 1780 Ù…Ù„ÙŠÙˆÙ†ÙŠØ±Ø§Ù‹ ÙÙŠ Ù„Ø¨Ù†Ø§Ù†. Ù…Ø§Ø°Ø§ Ù„Ùˆ ÙÙØ±Ø¶Øª Ø§Ù„...  unrelated       0\n",
              "9  Ø¯Ø¹Ø¨ÙˆÙ„ Ø­Ø¶Ø±ØªÙƒ Ù…Ù†Ùˆ Ø§Ù†Øª ÙˆØªØ·Ù„Ø¨ Ù…Ù† Ù‚Ø§Ø¦Ø¯ Ø¯ÙˆÙ„Ø© Ø¥Ø³Ù„Ø§Ù…ÙŠØ©...  info_news       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-436c3da8-ed19-47c5-a5a9-f45e21ffde7c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ø¨ÙŠÙ„ ØºÙŠØªØ³ ÙŠØªÙ„Ù‚Ù‰ Ù„Ù‚Ø§Ø­ #ÙƒÙˆÙÙŠØ¯19 Ù…Ù† ØºÙŠØ± ØªØµÙˆÙŠØ± Ø§Ù„Ø§Ø¨...</td>\n",
              "      <td>celebrity</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ÙˆØ²ÙŠØ± Ø§Ù„ØµØ­Ø© Ù„Ø­Ø¯ Ø§Ù„ÙŠÙˆÙ… ÙˆØªØ­Ø¯ÙŠØ¯Ø§ Ù‡Ù„Ø£ Ø¨Ù…Ø¤ØªÙ…Ø±ÙˆØ§ Ø§Ù„ØµØ­...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ù‚ÙˆÙ„ÙƒÙ†  Ø±Ø­ ÙŠÙƒÙˆÙ†Ùˆ Ø§Ø¯ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠØ© Ø¨ Ù„Ø¨Ù†Ø§Ù† Ù„Ù…Ø§ ÙŠÙˆØµÙ„ ...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#ØªØ±ÙƒÙŠØ§.. ÙˆØ²ÙŠØ± Ø§Ù„ØµØ­Ø© ÙØ®Ø± Ø§Ù„Ø¯ÙŠÙ† Ù‚ÙˆØ¬Ø© ÙŠØªÙ„Ù‚Ù‰ Ø£ÙˆÙ„ Ø¬...</td>\n",
              "      <td>celebrity</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ÙˆØ¦Ø§Ù… ÙˆÙ‡Ø§Ø¨ ÙŠØ´ØªÙ… Ø§Ù„Ø¯ÙˆÙ„ Ø§Ù„Ø®Ù„ÙŠØ¬ÙŠØ© ÙÙŠ ÙƒÙ„ Ø·Ù„Ø© Ø§Ø¹Ù„Ø§Ù…ÙŠ...</td>\n",
              "      <td>personal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ù„Ù‚Ø§Ø­ #ÙƒÙˆØ±ÙˆÙ†Ø§ ÙÙŠ Ø£Ù…ÙŠØ±ÙƒØ§.. Ù‚Ù„Ù‚ Ù…ØªØ²Ø§ÙŠØ¯ Ù…Ù† \"Ø§Ù„ØªÙˆØ²ÙŠ...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ù„Ø¨Ù†Ø§Ù† Ø§Ø´ØªØ±Ù‰ Ù…Ù„ÙŠÙˆÙ†Ø§Ù† Ù„Ù‚Ø§Ø­ Ø§Ù…Ø±ÙŠÙƒÙŠ Ø§Ø°Ø§ Ø´Ù„Ù†Ø§ ÙŠÙ„ÙŠ Ø¹...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Ù…Ù† Ø¹ÙˆØ§Ø±Ø¶ Ù„Ù‚Ø§Ø­ ÙƒÙˆØ±ÙˆÙ†Ø§&lt;LF&gt;Ù‡Ùˆ ØªÙ‡ÙƒÙŠØ± Ø­Ø³Ø§Ø¨Ùƒ Ø¹ØªÙˆÙŠØªØ±&lt;...</td>\n",
              "      <td>personal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ù‡Ù†Ø§Ùƒ 1780 Ù…Ù„ÙŠÙˆÙ†ÙŠØ±Ø§Ù‹ ÙÙŠ Ù„Ø¨Ù†Ø§Ù†. Ù…Ø§Ø°Ø§ Ù„Ùˆ ÙÙØ±Ø¶Øª Ø§Ù„...</td>\n",
              "      <td>unrelated</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Ø¯Ø¹Ø¨ÙˆÙ„ Ø­Ø¶Ø±ØªÙƒ Ù…Ù†Ùˆ Ø§Ù†Øª ÙˆØªØ·Ù„Ø¨ Ù…Ù† Ù‚Ø§Ø¦Ø¯ Ø¯ÙˆÙ„Ø© Ø¥Ø³Ù„Ø§Ù…ÙŠØ©...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-436c3da8-ed19-47c5-a5a9-f45e21ffde7c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-436c3da8-ed19-47c5-a5a9-f45e21ffde7c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-436c3da8-ed19-47c5-a5a9-f45e21ffde7c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V9-M9z4jW1g",
        "outputId": "91a470e9-0c2c-4699-d85a-1c92ceaf636b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text   category  stance\n",
              "0  #Ù…Ø±ÙŠÙ…_Ø±Ø¬ÙˆÙŠ: <LF>Ø­Ø¸Ø± Ø®Ø§Ù…Ù†Ø¦ÙŠ Ø§Ù„Ù…Ø¬Ø±Ù… Ø´Ø±Ø§Ø¡ #Ù„Ù‚Ø§Ø­_Ùƒ...  info_news       1\n",
              "1  #Ø§Ù„ØµØ­Ø©:<LF>â€¢ØªÙ… Ø¥Ø¹Ø·Ø§Ø¡ 259.530 Ø¬Ø±Ø¹Ø© Ù…Ù† Ù„Ù‚Ø§Ø­ #ÙƒÙˆØ±...       plan       1\n",
              "2  #Ø®Ø§Ø¯Ù…_Ø§Ù„Ø­Ø±Ù…ÙŠÙ† - Ø­ÙØ¸Ù‡ Ø§Ù„Ù„Ù‡ - ÙŠØªÙ„Ù‚Ù‰ Ø§Ù„Ø¬Ø±Ø¹Ø© Ø§Ù„Ø£ÙˆÙ„...  celebrity       1\n",
              "3  #Ø§Ù„ØµØ­Ù‡_Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠÙ‡: Ù„Ù‚Ø§Ø­Ø§Øª #ÙƒÙˆØ±ÙˆÙ†Ø§ Ø¢Ù…Ù†Ø© ÙˆÙ„Ø§ Ø®ÙˆÙ Ù…...  info_news       1\n",
              "4  #ÙˆØ²ÙŠØ±Ø©_Ø§Ù„ØµØ­Ø© \"#Ù‡Ø§Ù„Ø©_Ø²Ø§ÙŠØ¯\" ØªÙ‚ÙˆÙ„ Ø¥Ù†Ù‡ ÙŠØ¬Ø±Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø©...  info_news       1\n",
              "5  2ï¸âƒ£ ÙˆØ§Ù†ØªÙ‡Ù‰ Ø§Ù„ÙØ±ÙŠÙ‚ Ù…Ù† Ø§Ù„Ø¯Ø±Ø§Ø³Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø³Ø±ÙŠØ±ÙŠØ© ÙˆÙ†Ø´...  info_news       1\n",
              "6  Ø¹Ø§Ø¬Ù„ ğŸ”´ <LF>.<LF><LF>.<LF><LF>ÙˆØ²Ø§Ø±Ø© Ø§Ù„ØµØ­Ø© :<LF>...       plan       1\n",
              "7  #ÙÙŠØ¯ÙŠÙˆ | Ø§Ù„Ø³ÙÙŠØ± Ø§Ù„Ø£Ù…ÙŠØ±ÙƒÙŠ Ù„Ø¯Ù‰ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ø¨Ø¹Ø¯ ØªÙ„Ù‚ÙŠ...  info_news       1\n",
              "8  ØªØµØ±ÙŠØ­Ø§Øª ÙˆØ¨Ø³ Ø§Ù„Ø­ÙƒÙˆÙ…Ø© Ù…Ø¹ Ø§Ù„Ø³ÙŠØ³ÙŠ Ø¹Ù„ÙŠ Ø­Ø³Ø¨ Ø§Ù„Ù„Ù‚Ø·Ø©! ...  info_news       0\n",
              "9  Ø§Ù„Ø§ØªØ­Ø§Ø¯ Ø§Ù„Ø§ÙˆØ±ÙˆØ¨ÙŠ ØªÙØ§ÙˆØ¶ Ù„Ø´Ø±Ø§Ø¡ Ù„Ù‚Ø§Ø­Ø§Øª Ø§Ù„ÙƒÙˆØ±ÙˆÙ†Ø§ Ù…...  info_news       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13e401c0-febf-41dc-9588-f4e18147d3ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#Ù…Ø±ÙŠÙ…_Ø±Ø¬ÙˆÙŠ: &lt;LF&gt;Ø­Ø¸Ø± Ø®Ø§Ù…Ù†Ø¦ÙŠ Ø§Ù„Ù…Ø¬Ø±Ù… Ø´Ø±Ø§Ø¡ #Ù„Ù‚Ø§Ø­_Ùƒ...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#Ø§Ù„ØµØ­Ø©:&lt;LF&gt;â€¢ØªÙ… Ø¥Ø¹Ø·Ø§Ø¡ 259.530 Ø¬Ø±Ø¹Ø© Ù…Ù† Ù„Ù‚Ø§Ø­ #ÙƒÙˆØ±...</td>\n",
              "      <td>plan</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#Ø®Ø§Ø¯Ù…_Ø§Ù„Ø­Ø±Ù…ÙŠÙ† - Ø­ÙØ¸Ù‡ Ø§Ù„Ù„Ù‡ - ÙŠØªÙ„Ù‚Ù‰ Ø§Ù„Ø¬Ø±Ø¹Ø© Ø§Ù„Ø£ÙˆÙ„...</td>\n",
              "      <td>celebrity</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#Ø§Ù„ØµØ­Ù‡_Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠÙ‡: Ù„Ù‚Ø§Ø­Ø§Øª #ÙƒÙˆØ±ÙˆÙ†Ø§ Ø¢Ù…Ù†Ø© ÙˆÙ„Ø§ Ø®ÙˆÙ Ù…...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#ÙˆØ²ÙŠØ±Ø©_Ø§Ù„ØµØ­Ø© \"#Ù‡Ø§Ù„Ø©_Ø²Ø§ÙŠØ¯\" ØªÙ‚ÙˆÙ„ Ø¥Ù†Ù‡ ÙŠØ¬Ø±Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø©...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2ï¸âƒ£ ÙˆØ§Ù†ØªÙ‡Ù‰ Ø§Ù„ÙØ±ÙŠÙ‚ Ù…Ù† Ø§Ù„Ø¯Ø±Ø§Ø³Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø³Ø±ÙŠØ±ÙŠØ© ÙˆÙ†Ø´...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ø¹Ø§Ø¬Ù„ ğŸ”´ &lt;LF&gt;.&lt;LF&gt;&lt;LF&gt;.&lt;LF&gt;&lt;LF&gt;ÙˆØ²Ø§Ø±Ø© Ø§Ù„ØµØ­Ø© :&lt;LF&gt;...</td>\n",
              "      <td>plan</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>#ÙÙŠØ¯ÙŠÙˆ | Ø§Ù„Ø³ÙÙŠØ± Ø§Ù„Ø£Ù…ÙŠØ±ÙƒÙŠ Ù„Ø¯Ù‰ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ø¨Ø¹Ø¯ ØªÙ„Ù‚ÙŠ...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ØªØµØ±ÙŠØ­Ø§Øª ÙˆØ¨Ø³ Ø§Ù„Ø­ÙƒÙˆÙ…Ø© Ù…Ø¹ Ø§Ù„Ø³ÙŠØ³ÙŠ Ø¹Ù„ÙŠ Ø­Ø³Ø¨ Ø§Ù„Ù„Ù‚Ø·Ø©! ...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Ø§Ù„Ø§ØªØ­Ø§Ø¯ Ø§Ù„Ø§ÙˆØ±ÙˆØ¨ÙŠ ØªÙØ§ÙˆØ¶ Ù„Ø´Ø±Ø§Ø¡ Ù„Ù‚Ø§Ø­Ø§Øª Ø§Ù„ÙƒÙˆØ±ÙˆÙ†Ø§ Ù…...</td>\n",
              "      <td>info_news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13e401c0-febf-41dc-9588-f4e18147d3ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13e401c0-febf-41dc-9588-f4e18147d3ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13e401c0-febf-41dc-9588-f4e18147d3ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dev.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZY3ifXHjW1h",
        "outputId": "06ed7b47-3f4a-4742-a911-e4e50ec564f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6988,) (6988,) (6988,)\n",
            "(1000,) (1000,) (1000,)\n"
          ]
        }
      ],
      "source": [
        "text_train, category_train, stance_train = np.array(train['text']), np.array(train['category']), np.array(train['stance'])\n",
        "text_dev, category_dev, stance_dev = np.array(dev['text']), np.array(dev['category']), np.array(dev['stance'])\n",
        "\n",
        "print(text_train.shape, category_train.shape, stance_train.shape)\n",
        "print(text_dev.shape, category_dev.shape, stance_dev.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install arabert\n",
        "!pip install transformers\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "model_name=\"aubmindlab/bert-base-arabertv02-twitter\"\n",
        "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
        "\n",
        "text = \"ÙˆÙ„Ù† Ù†Ø¨Ø§Ù„Øº Ø¥Ø°Ø§ Ù‚Ù„Ù†Ø§ Ø¥Ù† Ù‡Ø§ØªÙ Ø£Ùˆ ÙƒÙ…Ø¨ÙŠÙˆØªØ± Ø§Ù„Ù…ÙƒØªØ¨ ÙÙŠ Ø²Ù…Ù†Ù†Ø§ Ù‡Ø°Ø§ Ø¶Ø±ÙˆØ±ÙŠ\"\n",
        "arabert_prep.preprocess(text)\n",
        "  \n",
        "tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabertv02-twitter\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"aubmindlab/bert-base-arabertv02-twitter\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtntXFJCSzCe",
        "outputId": "6b271c21-fbd0-4a47-9715-10cb2397e1a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: arabert in /usr/local/lib/python3.8/dist-packages (1.0.1)\n",
            "Requirement already satisfied: PyArabic in /usr/local/lib/python3.8/dist-packages (from arabert) (0.6.15)\n",
            "Requirement already satisfied: farasapy in /usr/local/lib/python3.8/dist-packages (from arabert) (0.0.14)\n",
            "Requirement already satisfied: emoji==1.4.2 in /usr/local/lib/python3.8/dist-packages (from arabert) (1.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from farasapy->arabert) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from farasapy->arabert) (4.64.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from PyArabic->arabert) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy->arabert) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy->arabert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy->arabert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy->arabert) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = text_train[0]\n",
        "bert_input = tokenizer(example_text, padding='max_length', max_length = 100, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "print(bert_input['input_ids'])\n",
        "print(bert_input['token_type_ids'])\n",
        "print(bert_input['attention_mask'])\n",
        "\n",
        "output = model(**bert_input)\n",
        "print(output.logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rMErblT8ZUI-",
        "outputId": "0f527917-a233-442c-cff0-843bd1efb0af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    2,  6941, 28652, 16136, 34495,    10, 17448,   196, 13593,   306,\n",
            "           650,  5166, 48342,   197,   139,   391,  5787,  7325,   197,   139,\n",
            "           391, 11474,   139,  7829,   213,  3616,   185, 54749,   305,  2858,\n",
            "         10639,   139,  1721,   338,  2779, 17613,  1686,   298,  5263,     1,\n",
            "           634,   889, 13591,  5175,   323, 28892,    20,    20,    20,  9110,\n",
            "           394,   418,  3682, 28892,  1422,   418,  6843, 36720,   306,  5263,\n",
            "         62279,    77,   221,   221,   178,   223,    31,     1,     1,    89,\n",
            "            20,    72,   219,     1,    54,   275,   272,   244,   244,   270,\n",
            "           260,   264,   268,   179,     3,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0]])\n",
            "torch.Size([1, 100, 64000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YajWdDqojW1k",
        "outputId": "38152471-fa95-45af-a8c5-e242020efcef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'requests', 'plan', 'advice', 'unrelated', 'info_news', 'celebrity', 'rumors', 'others', 'restrictions', 'personal'}\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "categories = set(category_train)\n",
        "print(categories)\n",
        "category2id = {word:i for i, word in enumerate(list(categories))}\n",
        "print(category2id['celebrity'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNLJr0azjW1l"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVlYMy5KjW1l"
      },
      "source": [
        "## BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnzUMpPajW1l"
      },
      "source": [
        "### Ideas to try\n",
        "1) bi-directional\n",
        "2) pre-training\n",
        "3) multi-layers\n",
        "4) BERT\n",
        "5) transformers notebook\n",
        "6) packed_padded_sequences\n",
        "7) pre-trained embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4d1daadjW1l"
      },
      "source": [
        "### Building Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_PIOF-0jW1l"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, x, y):\n",
        "\n",
        "    x = x.copy()\n",
        "\n",
        "    x = [arabert_prep.preprocess(text) for text in x]\n",
        "    self.X = [tokenizer(text, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\") for text in x]\n",
        "\n",
        "    self.Y = torch.tensor(y)\n",
        "\n",
        "    self.len = len(x)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.Y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j41ekReTjW1m"
      },
      "outputs": [],
      "source": [
        "stance_train_dataset = Dataset(text_train, stance_train + 1)\n",
        "category_train_dataset = Dataset(text_train, [category2id[category] for category in category_train])\n",
        "\n",
        "stance_dev_dataset = Dataset(text_dev, stance_dev + 1)\n",
        "category_dev_dataset = Dataset(text_dev, [category2id[category] for category in category_dev])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNWkSYiTjW1m"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, output_dim, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('aubmindlab/bert-base-arabertv02-twitter')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kny-X5tgjW1m"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt4mx_qdjW1m"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_dataset, train_dataloader, criterion, optimizer):\n",
        "\n",
        "  total_acc_train = 0\n",
        "  total_loss_train = 0\n",
        "\n",
        "  # for f1 score\n",
        "  y_true, y_pred = [], []\n",
        "\n",
        "  for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "    # print(\"input_ids\",train_input['input_ids'].shape)\n",
        "    # print(\"attention_mask\",train_input['attention_mask'].shape)\n",
        "\n",
        "    train_label = train_label.to(device)\n",
        "    mask = train_input['attention_mask'].to(device)\n",
        "    input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "    output = model(input_id, mask)\n",
        "\n",
        "    # print(output.shape)\n",
        "\n",
        "    batch_loss = criterion(output, train_label.long())\n",
        "    total_loss_train += batch_loss.item()\n",
        "\n",
        "    acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "    total_acc_train += acc\n",
        "\n",
        "    y_true += train_label.tolist() \n",
        "    y_pred += output.argmax(dim=1).tolist()\n",
        "\n",
        "    model.zero_grad()\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  # print(len(y_true), len(y_pred))\n",
        "  f1_macro_train = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "  return total_loss_train/len(train_dataset), total_acc_train/len(train_dataset), f1_macro_train"
      ],
      "metadata": {
        "id": "_551g6SEfIfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_dataset, test_dataloader, criterion):\n",
        "\n",
        "  total_acc_test = 0\n",
        "  total_loss_test = 0\n",
        "\n",
        "  # for f1 score\n",
        "  y_true, y_pred = [], []\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for test_input, test_label in test_dataloader:\n",
        "\n",
        "      test_label = test_label.to(device)\n",
        "\n",
        "      # print(test_input['input_ids'].shape)\n",
        "      # print(\"attention_mask\",train_input['attention_mask'].shape)\n",
        "\n",
        "      mask = test_input['attention_mask'].to(device)\n",
        "      input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "      output = model(input_id, mask)\n",
        "\n",
        "      # print(output.shape)\n",
        "\n",
        "      batch_loss = criterion(output, test_label.long())\n",
        "      total_loss_test += batch_loss.item()\n",
        "\n",
        "      acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "      total_acc_test += acc\n",
        "\n",
        "      y_true += test_label.tolist() \n",
        "      y_pred += output.argmax(dim=1).tolist()\n",
        "\n",
        "  # print(len(y_true)-1, len(y_pred)-1)\n",
        "  f1_macro_test = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "  return total_loss_test/len(test_dataset), total_acc_test/len(test_dataset), f1_macro_test"
      ],
      "metadata": {
        "id": "_Zg2G9hNDxh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate(model, train_dataset, val_dataset, learning_rate, epochs, model_name):\n",
        "\n",
        "  train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "  val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=2)\n",
        "\n",
        "  use_cuda = torch.cuda.is_available()\n",
        "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "\n",
        "  if use_cuda:\n",
        "    model = model.cuda()\n",
        "    criterion = criterion.cuda()\n",
        "\n",
        "  best_f1_macro = 0\n",
        "\n",
        "  for epoch_num in range(epochs):\n",
        "\n",
        "    loss_train, acc_train, f1_macro_train = train(model, train_dataset, train_dataloader, criterion, optimizer)\n",
        "    loss_val, acc_val, f1_macro_val = evaluate(model, val_dataset, val_dataloader, criterion)\n",
        "          \n",
        "    if f1_macro_val > best_f1_macro:\n",
        "      best_f1_macro = f1_macro_val\n",
        "    torch.save(model.state_dict(), f'Models/BERT/{model_name}/F1{f1_macro_val: .4f} Acc{acc_val: .4f}.pt')\n",
        "\n",
        "    print(\n",
        "        f'Epochs: {epoch_num + 1} \\\n",
        "        | Train Loss: {loss_train: .4f} \\\n",
        "        | Train Accuracy: {acc_train : .4f} \\\n",
        "        | Train F1_macro: {f1_macro_train: .4f} \\\n",
        "        | Val Loss: {loss_val: .4f} \\\n",
        "        | Val Accuracy: {acc_val: .4f} \\\n",
        "        | Val F1_macro: {f1_macro_val: .4f} \\\n",
        "        ')"
      ],
      "metadata": {
        "id": "umKC5RVvDzkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "OUTPUT_DIM = 3\n",
        "LR = 1e-6\n",
        "\n",
        "model = BertClassifier(OUTPUT_DIM)\n",
        "              \n",
        "train_evaluate(model, stance_train_dataset, stance_dev_dataset, LR, EPOCHS, 'Stance')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Se-eux3fiMd",
        "outputId": "2b9242e2-22ca-4f84-9df9-badd583be268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02-twitter were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:42<00:00,  4.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1         | Train Loss:  0.2729         | Train Accuracy:  0.7909         | Train F1_macro:  0.3660         | Val Loss:  0.2185         | Val Accuracy:  0.8170         | Val F1_macro:  0.4347         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:45<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2         | Train Loss:  0.2052         | Train Accuracy:  0.8240         | Train F1_macro:  0.4805         | Val Loss:  0.2032         | Val Accuracy:  0.8180         | Val F1_macro:  0.4936         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:44<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3         | Train Loss:  0.1780         | Train Accuracy:  0.8495         | Train F1_macro:  0.5832         | Val Loss:  0.1990         | Val Accuracy:  0.8310         | Val F1_macro:  0.5690         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:44<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4         | Train Loss:  0.1561         | Train Accuracy:  0.8745         | Train F1_macro:  0.6625         | Val Loss:  0.2036         | Val Accuracy:  0.8300         | Val F1_macro:  0.5731         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:45<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5         | Train Loss:  0.1275         | Train Accuracy:  0.9048         | Train F1_macro:  0.7633         | Val Loss:  0.2184         | Val Accuracy:  0.8300         | Val F1_macro:  0.6149         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "OUTPUT_DIM = 10\n",
        "LR = 1e-6\n",
        "\n",
        "model = BertClassifier(OUTPUT_DIM)\n",
        "              \n",
        "train_evaluate(model, category_train_dataset, category_dev_dataset, LR, EPOCHS, 'Category')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsZiircpVUpn",
        "outputId": "7c9cb052-fea6-487c-8049-d8b90af3c5a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02-twitter were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:44<00:00,  4.57it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 1         | Train Loss:  0.6729         | Train Accuracy:  0.5944         | Train F1_macro:  0.1758         | Val Loss:  0.5104         | Val Accuracy:  0.7050         | Val F1_macro:  0.2333         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:44<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2         | Train Loss:  0.5043         | Train Accuracy:  0.6895         | Train F1_macro:  0.2525         | Val Loss:  0.4733         | Val Accuracy:  0.7120         | Val F1_macro:  0.2630         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:45<00:00,  4.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3         | Train Loss:  0.4613         | Train Accuracy:  0.7109         | Train F1_macro:  0.2850         | Val Loss:  0.4639         | Val Accuracy:  0.7110         | Val F1_macro:  0.2675         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:45<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4         | Train Loss:  0.4290         | Train Accuracy:  0.7293         | Train F1_macro:  0.3080         | Val Loss:  0.4634         | Val Accuracy:  0.7120         | Val F1_macro:  0.2842         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:44<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5         | Train Loss:  0.3934         | Train Accuracy:  0.7523         | Train F1_macro:  0.3322         | Val Loss:  0.4729         | Val Accuracy:  0.6990         | Val F1_macro:  0.2844         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### continue Category"
      ],
      "metadata": {
        "id": "2qZuaPBrs5Ps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate(model, category_train_dataset, category_dev_dataset, LR, EPOCHS, 'Category')"
      ],
      "metadata": {
        "id": "B4gBxOqLW3tL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c820780-14eb-4d5c-f76d-5cfaca5f0f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:44<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1         | Train Loss:  0.3561         | Train Accuracy:  0.7772         | Train F1_macro:  0.3558         | Val Loss:  0.4803         | Val Accuracy:  0.6910         | Val F1_macro:  0.2865         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:44<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2         | Train Loss:  0.3163         | Train Accuracy:  0.8080         | Train F1_macro:  0.3857         | Val Loss:  0.5039         | Val Accuracy:  0.6530         | Val F1_macro:  0.2941         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:44<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3         | Train Loss:  0.2743         | Train Accuracy:  0.8343         | Train F1_macro:  0.4312         | Val Loss:  0.5184         | Val Accuracy:  0.6750         | Val F1_macro:  0.2835         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:44<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4         | Train Loss:  0.2347         | Train Accuracy:  0.8618         | Train F1_macro:  0.4790         | Val Loss:  0.5579         | Val Accuracy:  0.6400         | Val F1_macro:  0.3039         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:44<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5         | Train Loss:  0.1997         | Train Accuracy:  0.8857         | Train F1_macro:  0.5333         | Val Loss:  0.5774         | Val Accuracy:  0.6650         | Val F1_macro:  0.3230         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### continue Stance"
      ],
      "metadata": {
        "id": "LIua23Xns9VF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "OUTPUT_DIM = 3\n",
        "LR = 1e-6\n",
        "\n",
        "model = BertClassifier(OUTPUT_DIM)\n",
        "state = torch.load('Models/BERT/Stance/F1 0.6149 Acc 0.8300.pt')\n",
        "model.load_state_dict(state)\n",
        "              \n",
        "train_evaluate(model, stance_train_dataset, stance_dev_dataset, LR, EPOCHS, 'Stance')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Mp1VCYMm4KN",
        "outputId": "36193177-cb3b-4c78-9e7e-d43d5122ea44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02-twitter were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:46<00:00,  4.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1         | Train Loss:  0.0977         | Train Accuracy:  0.9315         | Train F1_macro:  0.8319         | Val Loss:  0.2343         | Val Accuracy:  0.8300         | Val F1_macro:  0.6209         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:44<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2         | Train Loss:  0.0743         | Train Accuracy:  0.9528         | Train F1_macro:  0.8848         | Val Loss:  0.2565         | Val Accuracy:  0.8350         | Val F1_macro:  0.6362         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:44<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3         | Train Loss:  0.0568         | Train Accuracy:  0.9664         | Train F1_macro:  0.9188         | Val Loss:  0.2794         | Val Accuracy:  0.8300         | Val F1_macro:  0.6506         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:44<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4         | Train Loss:  0.0434         | Train Accuracy:  0.9748         | Train F1_macro:  0.9412         | Val Loss:  0.3093         | Val Accuracy:  0.8120         | Val F1_macro:  0.6030         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3494/3494 [12:44<00:00,  4.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5         | Train Loss:  0.0355         | Train Accuracy:  0.9784         | Train F1_macro:  0.9493         | Val Loss:  0.3311         | Val Accuracy:  0.8260         | Val F1_macro:  0.6018         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "57OkEbTr40m4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f707ed687e1cc7dca614d866740125e744cc3f7963ec2d63a60d682146be2e45"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}